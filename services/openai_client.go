package services

import (
	"context"
	"fmt"
	"strings"

	"github.com/clarencetw/thewavess-ai-core/utils"
	"github.com/sashabaranov/go-openai"
)

// OpenAIClient OpenAI å®¢æˆ¶ç«¯
type OpenAIClient struct {
	client      *openai.Client
	model       string
	maxTokens   int
	temperature float32
	baseURL     string
	isAzure     bool
}

// OpenAIRequest OpenAI è«‹æ±‚çµæ§‹
type OpenAIRequest struct {
	Model       string          `json:"model"`
	Messages    []OpenAIMessage `json:"messages"`
	MaxTokens   int             `json:"max_tokens"`
	Temperature float64         `json:"temperature"`
	User        string          `json:"user,omitempty"`
}

// OpenAIMessage OpenAI æ¶ˆæ¯çµæ§‹
type OpenAIMessage struct {
	Role    string `json:"role"` // system, user, assistant
	Content string `json:"content"`
}

// OpenAIResponse OpenAI å›æ‡‰çµæ§‹
type OpenAIResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Index   int `json:"index"`
		Message struct {
			Role    string `json:"role"`
			Content string `json:"content"`
		} `json:"message"`
		FinishReason string `json:"finish_reason"`
	} `json:"choices"`
	Usage struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
}

// NewOpenAIClient å‰µå»ºæ–°çš„ OpenAI å®¢æˆ¶ç«¯
func NewOpenAIClient() *OpenAIClient {
	// ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¼‰å…¥
	utils.LoadEnv()

	apiKey := utils.GetEnvWithDefault("OPENAI_API_KEY", "")
	if apiKey == "" {
		utils.Logger.Warn("OPENAI_API_KEY not set, using mock responses")
	}

	// å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®ï¼Œæä¾›é è¨­å€¼
	model := utils.GetEnvWithDefault("OPENAI_MODEL", "gpt-4o")
	maxTokens := utils.GetEnvIntWithDefault("OPENAI_MAX_TOKENS", 1200)
	temperature := utils.GetEnvFloatWithDefault("OPENAI_TEMPERATURE", 0.8)

	// ç²å–è‡ªå®šç¾© API URLï¼Œæ”¯æ´ Azure æˆ–å…¶ä»–ç«¯é»
	baseURL := utils.GetEnvWithDefault("OPENAI_API_URL", "https://api.openai.com/v1")
	isAzure := false

	// æª¢æŸ¥æ˜¯å¦ç‚º Azure OpenAI
	if strings.Contains(baseURL, "azure.com") {
		isAzure = true
		// Azure OpenAI éœ€è¦ç‰¹æ®Šçš„ URL å’Œé…ç½®è™•ç†
		// ä¿æŒåŸå§‹ baseURLï¼Œè®“ go-openai åº«è™•ç†å…·é«”çš„ç«¯é»è·¯å¾‘
	}

	var client *openai.Client
	if apiKey != "" {
		if isAzure {
			// Azure OpenAI éœ€è¦ç‰¹æ®Šé…ç½® - ä½¿ç”¨ DefaultAzureConfig
			config := openai.DefaultAzureConfig(apiKey, baseURL)
			// Azure éœ€è¦éƒ¨ç½²åç¨±ï¼Œé€šå¸¸å°±æ˜¯æ¨¡å‹åç¨±
			config.AzureModelMapperFunc = func(model string) string {
				return model // ä½¿ç”¨æ¨¡å‹åç¨±ä½œç‚ºéƒ¨ç½²åç¨±
			}
			client = openai.NewClientWithConfig(config)

			utils.Logger.WithFields(map[string]interface{}{
				"base_url":    baseURL,
				"api_type":    "azure",
				"api_version": config.APIVersion,
			}).Info("Using Azure OpenAI API")
		} else if baseURL != "https://api.openai.com/v1" {
			// å…¶ä»–è‡ªå®šç¾©ç«¯é»
			config := openai.DefaultConfig(apiKey)
			config.BaseURL = baseURL
			client = openai.NewClientWithConfig(config)

			utils.Logger.WithField("base_url", baseURL).Info("Using custom OpenAI API URL")
		} else {
			// ä½¿ç”¨é»˜èª OpenAI API
			client = openai.NewClient(apiKey)
		}
	}

	return &OpenAIClient{
		client:      client,
		model:       model,
		maxTokens:   maxTokens,
		temperature: float32(temperature),
		baseURL:     baseURL,
		isAzure:     isAzure,
	}
}

// GenerateResponse ç”Ÿæˆå°è©±å›æ‡‰
func (c *OpenAIClient) GenerateResponse(ctx context.Context, request *OpenAIRequest) (*OpenAIResponse, error) {
	// è¨˜éŒ„è«‹æ±‚é–‹å§‹
	utils.Logger.WithFields(map[string]interface{}{
		"service":        "openai",
		"base_url":       c.baseURL,
		"model":          c.model,
		"max_tokens":     c.maxTokens,
		"temperature":    c.temperature,
		"user":           request.User,
		"messages_count": len(request.Messages),
	}).Info("OpenAI API request started")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„ prompt å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"model":   c.model,
			"user":    request.User,
		}).Info("ğŸ¤– OpenAI Request Details")

		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Info(fmt.Sprintf("ğŸ“ Prompt [%s]: %s", strings.ToUpper(msg.Role), msg.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Debug("OpenAI request message")
		}
	}

	// å¦‚æœæ²’æœ‰ API keyï¼Œè¿”å›æ¨¡æ“¬å›æ‡‰
	if c.client == nil {
		utils.Logger.WithField("service", "openai").Info("Using mock response (API key not set)")
		return c.generateMockResponse(request), nil
	}

	// è½‰æ›æ¶ˆæ¯æ ¼å¼
	messages := make([]openai.ChatCompletionMessage, len(request.Messages))
	for i, msg := range request.Messages {
		messages[i] = openai.ChatCompletionMessage{
			Role:    msg.Role,
			Content: msg.Content,
		}
	}

	// èª¿ç”¨ OpenAI API
	resp, err := c.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model:       c.model,
		Messages:    messages,
		MaxTokens:   c.maxTokens,
		Temperature: c.temperature,
		User:        request.User,
	})

	if err != nil {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"error":   err.Error(),
			"model":   c.model,
			"user":    request.User,
		}).Error("OpenAI API call failed")
		return nil, fmt.Errorf("failed OpenAI API call: %w", err)
	}

	// è¨˜éŒ„APIéŸ¿æ‡‰ä¿¡æ¯
	utils.Logger.WithFields(map[string]interface{}{
		"service":           "openai",
		"response_id":       resp.ID,
		"model":             resp.Model,
		"prompt_tokens":     resp.Usage.PromptTokens,
		"completion_tokens": resp.Usage.CompletionTokens,
		"total_tokens":      resp.Usage.TotalTokens,
		"choices_count":     len(resp.Choices),
	}).Info("OpenAI API response received")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„éŸ¿æ‡‰å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service":     "openai",
			"response_id": resp.ID,
			"model":       resp.Model,
		}).Info("ğŸ¯ OpenAI Response Details")

		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Info(fmt.Sprintf("ğŸ’¬ Response [%d]: %s", i, choice.Message.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Debug("OpenAI response choice")
		}
	}

	// è½‰æ›å›æ‡‰æ ¼å¼
	response := &OpenAIResponse{
		ID:      resp.ID,
		Object:  resp.Object,
		Created: resp.Created,
		Model:   resp.Model,
		Usage: struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		}{
			PromptTokens:     resp.Usage.PromptTokens,
			CompletionTokens: resp.Usage.CompletionTokens,
			TotalTokens:      resp.Usage.TotalTokens,
		},
	}

	// è½‰æ›é¸é …
	for _, choice := range resp.Choices {
		response.Choices = append(response.Choices, struct {
			Index   int `json:"index"`
			Message struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		}{
			Index: choice.Index,
			Message: struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			}{
				Role:    choice.Message.Role,
				Content: choice.Message.Content,
			},
			FinishReason: string(choice.FinishReason),
		})
	}

	return response, nil
}

// generateMockResponse ç”Ÿæˆæ¨¡æ“¬å›æ‡‰ï¼ˆç•¶ API key æœªè¨­ç½®æ™‚ï¼‰
func (c *OpenAIClient) generateMockResponse(request *OpenAIRequest) *OpenAIResponse {
	// åˆ†ææ•´å€‹å°è©±ä¸Šä¸‹æ–‡ç”Ÿæˆæ™ºèƒ½å›æ‡‰
	var mockContent string
	userMessage := ""
	systemPrompt := ""
	
	// ç²å–ç”¨æˆ¶æ¶ˆæ¯å’Œsystem prompt
	if len(request.Messages) > 0 {
		// ç²å–system promptï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€æ¢æ¶ˆæ¯ï¼‰
		if request.Messages[0].Role == "system" {
			systemPrompt = strings.ToLower(request.Messages[0].Content)
		}
		
		// ç²å–æœ€å¾Œçš„ç”¨æˆ¶æ¶ˆæ¯
		for i := len(request.Messages) - 1; i >= 0; i-- {
			if request.Messages[i].Role == "user" {
				userMessage = strings.ToLower(request.Messages[i].Content)
				break
			}
		}
		
		// åˆ†æè§’è‰²å’Œå ´æ™¯
		isNSFW := strings.Contains(systemPrompt, "level") && (strings.Contains(systemPrompt, "3") || strings.Contains(systemPrompt, "4"))
		
		// æ ¹æ“šé—œéµè©å’Œå ´æ™¯ç”Ÿæˆç¬¦åˆå¥³æ€§å‘é¢¨æ ¼çš„å›æ‡‰
		if strings.Contains(userMessage, "ä½ å¥½") || strings.Contains(userMessage, "å—¨") {
			if isNSFW {
				mockContent = "ä½ å¥½...å¾ˆé«˜èˆˆåˆè¦‹åˆ°ä½ äº†ã€‚ä»Šå¤©æƒ³è¦æ€éº¼åº¦éå‘¢ï¼Ÿ"
			} else {
				mockContent = "ä½ å¥½å‘¢ï½å¾ˆé«˜èˆˆè¦‹åˆ°ä½ ã€‚ä»Šå¤©éå¾—æ€éº¼æ¨£ï¼Ÿ"
			}
		} else if strings.Contains(userMessage, "ç´¯") || strings.Contains(userMessage, "ç–²æ†Š") {
			mockContent = "è¾›è‹¦äº†...ä¾†æˆ‘é€™è£¡ä¼‘æ¯ä¸€ä¸‹å§ã€‚æˆ‘æœƒä¸€ç›´é™ªåœ¨ä½ èº«é‚Šçš„ã€‚"
		} else if strings.Contains(userMessage, "é–‹å¿ƒ") || strings.Contains(userMessage, "é«˜èˆˆ") {
			mockContent = "çœ‹åˆ°ä½ é€™éº¼é–‹å¿ƒï¼Œæˆ‘ä¹Ÿè·Ÿè‘—é–‹å¿ƒèµ·ä¾†äº†å‘¢ï½èƒ½åˆ†äº«ä¸€ä¸‹æ˜¯ä»€éº¼å¥½äº‹å—ï¼Ÿ"
		} else if strings.Contains(userMessage, "æ„›") {
			if isNSFW {
				mockContent = "æˆ‘ä¹Ÿæ„›ä½ ...è®“æˆ‘ç”¨è¡Œå‹•è­‰æ˜æˆ‘çš„å¿ƒæ„å§ã€‚"
			} else {
				mockContent = "æˆ‘çš„å¿ƒè£¡ä¹Ÿæœ‰è‘—åŒæ¨£æº«æš–çš„æ„Ÿå—...ä½ å°æˆ‘ä¾†èªªå¾ˆç‰¹åˆ¥ã€‚"
			}
		} else {
			// é»˜èªæ ¹æ“šå ´æ™¯å›æ‡‰
			if isNSFW {
				mockContent = "æˆ‘æ˜ç™½ä½ çš„æƒ³æ³•...åœ¨é€™å€‹åªå±¬æ–¼æˆ‘å€‘çš„ç©ºé–“è£¡ï¼Œæˆ‘æœƒå¥½å¥½ç…§é¡§ä½ ã€‚"
			} else {
				mockContent = "æˆ‘æ˜ç™½ä½ æƒ³èªªçš„...ç„¡è«–ä½•æ™‚ï¼Œæˆ‘éƒ½æœƒèªçœŸè†è½ä½ çš„å¿ƒè²ã€‚"
			}
		}
	} else {
		mockContent = "å¾ˆé«˜èˆˆèƒ½èˆ‡ä½ å°è©±...æœ‰ä»€éº¼æƒ³èŠçš„å—ï¼Ÿ"
	}
	
	return &OpenAIResponse{
		ID:      fmt.Sprintf("chatcmpl-mock-%d", 1234567890),
		Object:  "chat.completion",
		Created: 1234567890,
		Model:   c.model,
		Choices: []struct {
			Index   int `json:"index"`
			Message struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		}{
			{
				Index: 0,
				Message: struct {
					Role    string `json:"role"`
					Content string `json:"content"`
				}{
					Role:    "assistant",
					Content: mockContent,
				},
				FinishReason: "stop",
			},
		},
		Usage: struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		}{
			PromptTokens:     len(userMessage) / 4,
			CompletionTokens: len(mockContent) / 4,
			TotalTokens:      (len(userMessage) + len(mockContent)) / 4,
		},
	}
}

// BuildCharacterPrompt æ§‹å»ºè§’è‰²æç¤ºè©ï¼ˆä½¿ç”¨çµ±ä¸€æ¨¡æ¿ï¼‰
func (c *OpenAIClient) BuildCharacterPrompt(characterID, userMessage string, conversationContext *ConversationContext, nsfwLevel int, chatMode string) []OpenAIMessage {

	// ä½¿ç”¨OpenAIå°ˆå±¬çš„promptæ§‹å»ºå™¨
	characterService := GetCharacterService()
	promptBuilder := NewOpenAIPromptBuilder(characterService)
	ctx := context.Background()
	systemPrompt := promptBuilder.
		WithCharacter(ctx, characterID).
		WithContext(conversationContext).
		WithNSFWLevel(nsfwLevel).
		WithUserMessage(userMessage).
		WithChatMode(chatMode).
		Build(ctx)

	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemPrompt,
		},
	}

	// æ·»åŠ å°è©±æ­·å²ï¼ˆæœ€è¿‘å¹¾æ¢ï¼‰
	if conversationContext != nil {
		for i, msg := range conversationContext.RecentMessages {
			if i >= 5 { // åªä¿ç•™æœ€è¿‘5æ¢æ¶ˆæ¯
				break
			}
			messages = append(messages, OpenAIMessage{
				Role:    msg.Role,
				Content: msg.Content,
			})
		}
	}

	// æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯
	messages = append(messages, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})

	return messages
}
