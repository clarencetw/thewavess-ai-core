package services

import (
	"context"
	"fmt"
	"strings"

	"github.com/clarencetw/thewavess-ai-core/utils"
	"github.com/openai/openai-go/v2"
	"github.com/openai/openai-go/v2/option"
)

// OpenAIClient OpenAI å®¢æˆ¶ç«¯
type OpenAIClient struct {
	client      openai.Client
	model       openai.ChatModel
	maxTokens   int
	temperature float64
	baseURL     string
}

// OpenAIRequest OpenAI è«‹æ±‚çµæ§‹
type OpenAIRequest struct {
	Model       string          `json:"model"`
	Messages    []OpenAIMessage `json:"messages"`
	MaxTokens   int             `json:"max_tokens"`
	Temperature float64         `json:"temperature"`
	User        string          `json:"user,omitempty"`
}

// OpenAIMessage OpenAI æ¶ˆæ¯çµæ§‹
type OpenAIMessage struct {
	Role    string `json:"role"` // system, user, assistant
	Content string `json:"content"`
}

// OpenAIResponse ä½¿ç”¨å®˜æ–¹ SDK çš„ ChatCompletion ä½œç‚ºéŸ¿æ‡‰é¡å‹
type OpenAIResponse = openai.ChatCompletion

// NewOpenAIClient å‰µå»ºæ–°çš„ OpenAI å®¢æˆ¶ç«¯
func NewOpenAIClient() *OpenAIClient {
	// ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¼‰å…¥
	utils.LoadEnv()

	apiKey := utils.GetEnvWithDefault("OPENAI_API_KEY", "")
	if apiKey == "" {
		utils.Logger.Fatal("OPENAI_API_KEY is required but not set in environment")
	}

	// å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®ï¼Œæä¾›é è¨­å€¼
	modelName := utils.GetEnvWithDefault("OPENAI_MODEL", "gpt-4o-mini")
	maxTokens := utils.GetEnvIntWithDefault("OPENAI_MAX_TOKENS", 1200)
	temperature := utils.GetEnvFloatWithDefault("OPENAI_TEMPERATURE", 0.8)

	// ç²å–è‡ªå®šç¾© API URL
	baseURL := utils.GetEnvWithDefault("OPENAI_API_URL", "https://api.openai.com/v1")

	// è¨­å®š model
	var model openai.ChatModel
	switch modelName {
	case "gpt-4o":
		model = openai.ChatModelGPT4o
	case "gpt-4o-mini":
		model = openai.ChatModelGPT4oMini
	case "gpt-4":
		model = openai.ChatModelGPT4
	case "gpt-3.5-turbo":
		model = openai.ChatModelGPT3_5Turbo
	default:
		model = openai.ChatModelGPT4oMini
	}

	var client openai.Client
	if baseURL != "https://api.openai.com/v1" {
		// è‡ªå®šç¾©ç«¯é»
		client = openai.NewClient(
			option.WithAPIKey(apiKey),
			option.WithBaseURL(baseURL),
		)
		utils.Logger.WithField("base_url", baseURL).Info("Using custom OpenAI API URL")
	} else {
		// ä½¿ç”¨é»˜èª OpenAI API
		client = openai.NewClient(
			option.WithAPIKey(apiKey),
		)
	}

	return &OpenAIClient{
		client:      client,
		model:       model,
		maxTokens:   maxTokens,
		temperature: temperature,
		baseURL:     baseURL,
	}
}

// GenerateResponse ç”Ÿæˆå°è©±å›æ‡‰
func (c *OpenAIClient) GenerateResponse(ctx context.Context, request *OpenAIRequest) (*OpenAIResponse, error) {
	// è¨˜éŒ„è«‹æ±‚é–‹å§‹
	utils.Logger.WithFields(map[string]interface{}{
		"service":        "openai",
		"base_url":       c.baseURL,
		"model":          c.model,
		"max_tokens":     c.maxTokens,
		"temperature":    c.temperature,
		"user":           request.User,
		"messages_count": len(request.Messages),
	}).Info("OpenAI API request started")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„ prompt å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"model":   c.model,
			"user":    request.User,
		}).Info("ğŸ¤– OpenAI Request Details")

		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Info(fmt.Sprintf("ğŸ“ Prompt [%s]: %s", strings.ToUpper(msg.Role), msg.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Debug("OpenAI request message")
		}
	}

	// è½‰æ›æ¶ˆæ¯æ ¼å¼
	messages := make([]openai.ChatCompletionMessageParamUnion, len(request.Messages))
	for i, msg := range request.Messages {
		switch msg.Role {
		case "system":
			messages[i] = openai.SystemMessage(msg.Content)
		case "user":
			messages[i] = openai.UserMessage(msg.Content)
		case "assistant":
			messages[i] = openai.AssistantMessage(msg.Content)
		default:
			messages[i] = openai.UserMessage(msg.Content)
		}
	}

	// å»ºç«‹ API åƒæ•¸
	params := openai.ChatCompletionNewParams{
		Model:       c.model,
		Messages:    messages,
		MaxTokens:   openai.Int(int64(c.maxTokens)),
		Temperature: openai.Float(c.temperature),
		User:        openai.String(request.User),
	}

	// å¯é¸åŠŸèƒ½ï¼šLogprobsï¼ˆèª¿è©¦å’Œåˆ†ææ¨¡å‹ä¿¡å¿ƒï¼‰
	if utils.GetEnvWithDefault("OPENAI_LOGPROBS", "false") == "true" {
		params.Logprobs = openai.Bool(true)
		if topLogprobs := utils.GetEnvIntWithDefault("OPENAI_TOP_LOGPROBS", 0); topLogprobs > 0 && topLogprobs <= 20 {
			params.TopLogprobs = openai.Int(int64(topLogprobs))
		}
	}

	// å¯é¸åŠŸèƒ½ï¼šæœå‹™å±¤ç´šæ§åˆ¶
	if serviceTier := utils.GetEnvWithDefault("OPENAI_SERVICE_TIER", ""); serviceTier != "" {
		switch serviceTier {
		case "auto", "default", "flex", "scale", "priority":
			params.ServiceTier = openai.ChatCompletionNewParamsServiceTier(serviceTier)
		}
	}

	// åŠ å…¥ç¨®å­åƒæ•¸ä»¥æé«˜ä¸€è‡´æ€§ï¼ˆå¯é¸ï¼‰
	if seed := utils.GetEnvWithDefault("OPENAI_SEED", ""); seed != "" {
		if seedInt := utils.GetEnvIntWithDefault("OPENAI_SEED", 0); seedInt > 0 {
			params.Seed = openai.Int(int64(seedInt))
		}
	}

	// èª¿ç”¨ OpenAI API
	resp, err := c.client.Chat.Completions.New(ctx, params)

	if err != nil {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"error":   err.Error(),
			"model":   string(c.model),
			"user":    request.User,
		}).Error("OpenAI API call failed")
		return nil, fmt.Errorf("failed OpenAI API call: %w", err)
	}

	// è¨ˆç®—ç°¡å–®æˆæœ¬ä¼°ç®—
	totalTokens := int(resp.Usage.TotalTokens)
	var costEstimate float64
	switch string(resp.Model) {
	case "gpt-4o":
		costEstimate = float64(totalTokens) * 0.000005 // $0.005 per 1K tokens
	case "gpt-4o-mini":
		costEstimate = float64(totalTokens) * 0.00000015 // $0.00015 per 1K tokens
	case "gpt-4":
		costEstimate = float64(totalTokens) * 0.00003 // $0.03 per 1K tokens
	case "gpt-3.5-turbo":
		costEstimate = float64(totalTokens) * 0.0000015 // $0.0015 per 1K tokens
	default:
		costEstimate = float64(totalTokens) * 0.000002 // Default estimate
	}

	// è¨˜éŒ„APIéŸ¿æ‡‰ä¿¡æ¯ï¼ŒåŒ…å« token ä½¿ç”¨å’Œæˆæœ¬
	logFields := map[string]interface{}{
		"service":           "openai",
		"response_id":       resp.ID,
		"model":             string(resp.Model),
		"object":            string(resp.Object),
		"created":           resp.Created,
		"prompt_tokens":     resp.Usage.PromptTokens,
		"completion_tokens": resp.Usage.CompletionTokens,
		"total_tokens":      resp.Usage.TotalTokens,
		"cost_usd":          fmt.Sprintf("$%.6f", costEstimate),
		"choices_count":     len(resp.Choices),
	}

	// åŠ å…¥ finish_reason å’Œå…§å®¹éæ¿¾ç›¸é—œè³‡è¨Š
	if len(resp.Choices) > 0 {
		finishReason := string(resp.Choices[0].FinishReason)
		logFields["finish_reason"] = finishReason

		// æ¨™è¨˜æ˜¯å¦è¢«å…§å®¹éæ¿¾å™¨é˜»æ“‹
		if finishReason == "content_filter" {
			logFields["content_filtered"] = true
		}
	}

	// SystemFingerprint å·²è¢«å®˜æ–¹æ¨™è¨˜ç‚º deprecatedï¼Œä¸å†è¨˜éŒ„

	// åŠ å…¥æœå‹™å±¤ç´šè³‡è¨Šï¼ˆå¯èƒ½å½±éŸ¿å…§å®¹éæ¿¾ï¼‰
	if resp.ServiceTier != "" {
		logFields["service_tier"] = string(resp.ServiceTier)
	}

	// è¨˜éŒ„ Logprobs è³‡è¨Šï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
	if len(resp.Choices) > 0 {
		logprobs := resp.Choices[0].Logprobs
		if logprobs.Content != nil && len(logprobs.Content) > 0 {
			logFields["logprobs_enabled"] = true
			logFields["logprobs_tokens"] = len(logprobs.Content)
		}
	}

	// åŠ å…¥ seed åƒæ•¸ï¼ˆå¦‚æœæœ‰è¨­å®šï¼‰
	if seed := utils.GetEnvWithDefault("OPENAI_SEED", ""); seed != "" {
		logFields["seed_used"] = seed
	}

	utils.Logger.WithFields(logFields).Info("OpenAI API response received")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„éŸ¿æ‡‰å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service":     "openai",
			"response_id": resp.ID,
			"model":       string(resp.Model),
		}).Info("ğŸ¯ OpenAI Response Details")

		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  string(choice.FinishReason),
				"content_length": len(choice.Message.Content),
			}).Info(fmt.Sprintf("ğŸ’¬ Response [%d]: %s", i, choice.Message.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  string(choice.FinishReason),
				"content_length": len(choice.Message.Content),
			}).Debug("OpenAI response choice")
		}
	}

	// ç›´æ¥è¿”å›å®˜æ–¹ SDK çš„éŸ¿æ‡‰çµæ§‹
	return resp, nil
}

// BuildCharacterPrompt æ§‹å»ºè§’è‰²æç¤ºè©
func (c *OpenAIClient) BuildCharacterPrompt(characterID, userMessage string, conversationContext *ConversationContext, nsfwLevel int, chatMode string) []OpenAIMessage {

	// ç²å–è§’è‰²è³‡æ–™
	characterService := GetCharacterService()
	ctx := context.Background()
	dbCharacter, err := characterService.GetCharacterDB(ctx, characterID)
	if err != nil {
		utils.Logger.WithError(err).Error("Failed to get character for prompt building")
		return nil
	}

	// ä½¿ç”¨OpenAIå°ˆå±¬çš„promptæ§‹å»ºå™¨
	promptBuilder := NewOpenAIPromptBuilder(characterService)
	promptBuilder.WithCharacter(dbCharacter)
	promptBuilder.WithContext(conversationContext)
	promptBuilder.WithNSFWLevel(nsfwLevel)
	promptBuilder.WithUserMessage(userMessage)
	promptBuilder.WithChatMode(chatMode)
	systemPrompt := promptBuilder.Build()

	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemPrompt,
		},
	}

	// æ·»åŠ å°è©±æ­·å²ï¼ˆæœ€è¿‘å¹¾æ¢ï¼‰
    if conversationContext != nil {
        // åƒ…ä¿ç•™æœ€è¿‘2å‰‡æ­·å²ï¼ˆèˆŠ -> æ–°ï¼‰
        count := len(conversationContext.RecentMessages)
        if count > 2 { count = 2 }
        for i := count - 1; i >= 0; i-- {
            msg := conversationContext.RecentMessages[i]
            messages = append(messages, OpenAIMessage{Role: msg.Role, Content: msg.Content})
        }
    }

    // æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯ï¼ˆé¿å…èˆ‡æ­·å²çš„æœ€å¾Œä¸€å‰‡ç”¨æˆ¶è¨Šæ¯é‡è¤‡ï¼‰
    shouldAppendUser := true
    if conversationContext != nil && len(conversationContext.RecentMessages) > 0 {
        latest := conversationContext.RecentMessages[0] // æœ€æ–°åœ¨å‰
        if latest.Role == "user" && strings.TrimSpace(latest.Content) == strings.TrimSpace(userMessage) {
            shouldAppendUser = false
        }
    }
    if shouldAppendUser {
        messages = append(messages, OpenAIMessage{Role: "user", Content: userMessage})
    }

	return messages
}
