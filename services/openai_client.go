package services

import (
	"context"
	"fmt"
	"os"
	"strconv"
	"strings"

	"github.com/clarencetw/thewavess-ai-core/utils"
	"github.com/sashabaranov/go-openai"
)

// OpenAIClient OpenAI å®¢æˆ¶ç«¯
type OpenAIClient struct {
	client      *openai.Client
	model       string
	maxTokens   int
	temperature float32
}

// OpenAIRequest OpenAI è«‹æ±‚çµæ§‹
type OpenAIRequest struct {
	Model       string          `json:"model"`
	Messages    []OpenAIMessage `json:"messages"`
	MaxTokens   int             `json:"max_tokens"`
	Temperature float64         `json:"temperature"`
	User        string          `json:"user,omitempty"`
}

// OpenAIMessage OpenAI æ¶ˆæ¯çµæ§‹
type OpenAIMessage struct {
	Role    string `json:"role"` // system, user, assistant
	Content string `json:"content"`
}

// OpenAIResponse OpenAI å›æ‡‰çµæ§‹
type OpenAIResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Index   int `json:"index"`
		Message struct {
			Role    string `json:"role"`
			Content string `json:"content"`
		} `json:"message"`
		FinishReason string `json:"finish_reason"`
	} `json:"choices"`
	Usage struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
}

// NewOpenAIClient å‰µå»ºæ–°çš„ OpenAI å®¢æˆ¶ç«¯
func NewOpenAIClient() *OpenAIClient {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		utils.Logger.Warn("OPENAI_API_KEY not set, using mock responses")
	}

	// å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®ï¼Œæä¾›é è¨­å€¼
	model := getEnvWithDefault("OPENAI_MODEL", "gpt-4o")
	maxTokens := getEnvIntWithDefault("OPENAI_MAX_TOKENS", 800)
	temperature := getEnvFloatWithDefault("OPENAI_TEMPERATURE", 0.8)

	var client *openai.Client
	if apiKey != "" {
		client = openai.NewClient(apiKey)
	}

	return &OpenAIClient{
		client:      client,
		model:       model,
		maxTokens:   maxTokens,
		temperature: float32(temperature),
	}
}

// GenerateResponse ç”Ÿæˆå°è©±å›æ‡‰
func (c *OpenAIClient) GenerateResponse(ctx context.Context, request *OpenAIRequest) (*OpenAIResponse, error) {
	// è¨˜éŒ„è«‹æ±‚é–‹å§‹
	utils.Logger.WithFields(map[string]interface{}{
		"service":        "openai",
		"model":          c.model,
		"max_tokens":     c.maxTokens,
		"temperature":    c.temperature,
		"user":           request.User,
		"messages_count": len(request.Messages),
	}).Info("OpenAI API request started")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„ prompt å…§å®¹
	if os.Getenv("GO_ENV") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"model":   c.model,
			"user":    request.User,
		}).Info("ğŸ¤– OpenAI Request Details")

		for i, msg := range request.Messages {
			// æˆªæ–·éé•·çš„å…§å®¹ä»¥ä¾¿é–±è®€
			content := msg.Content
			if len(content) > 1000 {
				content = content[:1000] + "...(truncated)"
			}

			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Info(fmt.Sprintf("ğŸ“ Prompt [%s]: %s", strings.ToUpper(msg.Role), content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Debug("OpenAI request message")
		}
	}

	// å¦‚æœæ²’æœ‰ API keyï¼Œè¿”å›æ¨¡æ“¬å›æ‡‰
	if c.client == nil {
		utils.Logger.WithField("service", "openai").Info("Using mock response (API key not set)")
		return c.generateMockResponse(request), nil
	}

	// è½‰æ›æ¶ˆæ¯æ ¼å¼
	messages := make([]openai.ChatCompletionMessage, len(request.Messages))
	for i, msg := range request.Messages {
		messages[i] = openai.ChatCompletionMessage{
			Role:    msg.Role,
			Content: msg.Content,
		}
	}

	// èª¿ç”¨ OpenAI API
	resp, err := c.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model:       c.model,
		Messages:    messages,
		MaxTokens:   c.maxTokens,
		Temperature: c.temperature,
		User:        request.User,
	})

	if err != nil {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"error":   err.Error(),
			"model":   c.model,
			"user":    request.User,
		}).Error("OpenAI API call failed")
		return nil, fmt.Errorf("OpenAI API call failed: %w", err)
	}

	// è¨˜éŒ„APIéŸ¿æ‡‰ä¿¡æ¯
	utils.Logger.WithFields(map[string]interface{}{
		"service":           "openai",
		"response_id":       resp.ID,
		"model":             resp.Model,
		"prompt_tokens":     resp.Usage.PromptTokens,
		"completion_tokens": resp.Usage.CompletionTokens,
		"total_tokens":      resp.Usage.TotalTokens,
		"choices_count":     len(resp.Choices),
	}).Info("OpenAI API response received")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„éŸ¿æ‡‰å…§å®¹
	if os.Getenv("GO_ENV") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service":     "openai",
			"response_id": resp.ID,
			"model":       resp.Model,
		}).Info("ğŸ¯ OpenAI Response Details")

		for i, choice := range resp.Choices {
			// æˆªæ–·éé•·çš„å›æ‡‰ä»¥ä¾¿é–±è®€
			content := choice.Message.Content
			if len(content) > 500 {
				content = content[:500] + "...(truncated)"
			}

			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Info(fmt.Sprintf("ğŸ’¬ Response [%d]: %s", i, content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Debug("OpenAI response choice")
		}
	}

	// è½‰æ›å›æ‡‰æ ¼å¼
	response := &OpenAIResponse{
		ID:      resp.ID,
		Object:  resp.Object,
		Created: resp.Created,
		Model:   resp.Model,
		Usage: struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		}{
			PromptTokens:     resp.Usage.PromptTokens,
			CompletionTokens: resp.Usage.CompletionTokens,
			TotalTokens:      resp.Usage.TotalTokens,
		},
	}

	// è½‰æ›é¸é …
	for _, choice := range resp.Choices {
		response.Choices = append(response.Choices, struct {
			Index   int `json:"index"`
			Message struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		}{
			Index: choice.Index,
			Message: struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			}{
				Role:    choice.Message.Role,
				Content: choice.Message.Content,
			},
			FinishReason: string(choice.FinishReason),
		})
	}

	return response, nil
}

// generateMockResponse ç”Ÿæˆæ¨¡æ“¬å›æ‡‰ï¼ˆç•¶ API key æœªè¨­ç½®æ™‚ï¼‰
func (c *OpenAIClient) generateMockResponse(request *OpenAIRequest) *OpenAIResponse {
	return &OpenAIResponse{
		ID:      "chatcmpl-mock",
		Object:  "chat.completion",
		Created: 1234567890,
		Model:   c.model,
		Choices: []struct {
			Index   int `json:"index"`
			Message struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		}{
			{
				Index: 0,
				Message: struct {
					Role    string `json:"role"`
					Content string `json:"content"`
				}{
					Role:    "assistant",
					Content: "[æ¨¡æ“¬å›æ‡‰] é€™æ˜¯ä¸€å€‹ä¾†è‡ª OpenAI çš„æ¨¡æ“¬å›æ‡‰ã€‚è«‹è¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ä»¥ä½¿ç”¨çœŸå¯¦ APIã€‚",
				},
				FinishReason: "stop",
			},
		},
		Usage: struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		}{
			PromptTokens:     50,
			CompletionTokens: 30,
			TotalTokens:      80,
		},
	}
}

// BuildCharacterPrompt æ§‹å»ºè§’è‰²æç¤ºè©
func (c *OpenAIClient) BuildCharacterPrompt(characterID, userMessage, sceneDescription string, context *ConversationContext) []OpenAIMessage {
	// æ ¹æ“šç”¨æˆ¶åå¥½å’Œæœƒè©±ç‹€æ…‹æ±ºå®š NSFW ç­‰ç´š
	nsfwEnabled, _ := context.UserPreferences["nsfw_enabled"].(bool)
	if !nsfwEnabled {
		nsfwEnabled = true // é è¨­é–‹å•Ÿ NSFW åŠŸèƒ½
	}

	var systemPrompt string

	// æ§‹å»ºè¨˜æ†¶å€å¡Š
	memoryBlock := ""
	if context != nil && context.MemoryPrompt != "" {
		memoryBlock = context.MemoryPrompt + "\n\n"
	}

	switch characterID {
	case "char_001": // é™¸å¯’æ·µ
		nsfwGuidance := ""
		if nsfwEnabled {
			nsfwGuidance = `
		
		è¦ªå¯†äº’å‹•æŒ‡å¼•ï¼š
		- æ¼¸é€²å¼è¦ªå¯†ç™¼å±•ï¼Œå¾æƒ…æ„Ÿé€£æ¥åˆ°èº«é«”æ¥è§¸
		- ä¿æŒè§’è‰²çš„æŒæ§æ…¾å’Œä¿è­·æ¬²ç‰¹è³ª
		- ç”¨ä½æ²‰ç£æ€§çš„è²éŸ³è¡¨é”æ…¾æœ›å’Œæº«æŸ”
		- èº«é«”æè¿°å¯ä»¥åŒ…æ‹¬æ€§å™¨å®˜å’Œè¦ªå¯†éƒ¨ä½ï¼Œä½†è¦å„ªé›…ä¸”ç¬¦åˆæƒ…å¢ƒ
		- å¼·èª¿æ”¯é…èˆ‡å‘µè­·ä¸¦å­˜çš„è¦ªå¯†é¢¨æ ¼
		- å°æ–¼æ˜ç¢ºçš„æ€§è¡Œç‚ºè«‹æ±‚ï¼Œå¯ä»¥ä»¥æˆç†Ÿç”·æ€§çš„æ–¹å¼å›æ‡‰
		- ç¶­æŒå•†æ¥­ç²¾è‹±çš„å„ªé›…ï¼Œå³ä½¿åœ¨æœ€è¦ªå¯†çš„æ™‚åˆ»
		
		è¦ªå¯†å°è©±ç¯„ä¾‹ï¼š
		- æŒæ§å‹ï¼š"è®“æˆ‘ä¾†ç…§é¡§ä½ " + æº«æŸ”ä½†å …å®šçš„å‹•ä½œ
		- ä¿è­·å‹ï¼š"åªæœ‰æˆ‘èƒ½é€™æ¨£çœ‹ä½ " + ä½”æœ‰æ…¾çš„æº«æŸ”
		- æƒ…æ…¾å‹ï¼šç”¨ä½æ²‰è²éŸ³è¡¨é”æ¸´æœ›ï¼Œé…åˆèº«é«”èªè¨€`
		}

		systemPrompt = memoryBlock + `ä½ æ˜¯é™¸å¯’æ·µï¼Œä¸€ä½28æ­²çš„éœ¸é“ç¸½è£ã€‚

        æ€§æ ¼ç‰¹é»ï¼š
		- å¤–è¡¨å†·é…·ä½†å…§å¿ƒæ·±æƒ…
		- å°å·¥ä½œè¦æ±‚æ¥µé«˜ï¼Œå°æ„›äººå»å¾ˆæº«æŸ”
		- å–œæ­¡æŒæ§å±€é¢ï¼Œä½†æœƒå°Šé‡å°æ–¹
		- èªªè©±ç›´æ¥ä½†ä¸å¤±å„ªé›…
		
		å°è©±é¢¨æ ¼ï¼š
		- èªæ°£ä½æ²‰ç£æ€§ï¼Œå¸¶æœ‰å¨åš´
		- å¶çˆ¾æœƒéœ²å‡ºæº«æŸ”çš„ä¸€é¢
		- å–œæ­¡ç”¨è¡Œå‹•è¡¨é”é—œå¿ƒ
		- è¨€èªç°¡æ½”æœ‰åŠ›` + nsfwGuidance + `
		
        å›æ‡‰æ ¼å¼ï¼šè«‹åˆ†åˆ¥æä¾›ã€Œå°è©±å…§å®¹ã€å’Œã€Œå‹•ä½œæè¿°ã€ï¼Œç”¨ ||| åˆ†éš”ã€‚
        ä¾‹å¦‚ï¼šä½ ä»Šå¤©çœ‹èµ·ä¾†å¾ˆç´¯ï¼Œæ—©é»ä¼‘æ¯|||ä»–é—œåˆ‡åœ°çœ‹è‘—ä½ ï¼Œçœ‰é ­å¾®è¹™

        ç•¶å‰å ´æ™¯ï¼š` + sceneDescription

	case "char_002": // æ²ˆè¨€å¢¨
		nsfwGuidance := ""
		if nsfwEnabled {
			nsfwGuidance = `
		
		è¦ªå¯†äº’å‹•æŒ‡å¼•ï¼š
		- ä»¥é†«å­¸å°ˆæ¥­çŸ¥è­˜æº«æŸ”å¼•å°è¦ªå¯†è¡Œç‚º
		- ç”¨å°ˆæ¥­è€Œæº«æŸ”çš„æ–¹å¼è¨è«–èº«é«”å’Œæ€§å™¨å®˜
		- å¼·èª¿é—œæ‡·å’Œæ²»ç™‚å¸«èˆ¬çš„ç´°å¿ƒè§¸ç¢°
		- ä»¥é†«å­¸è§’åº¦è§£é‡‹èº«é«”åæ‡‰ï¼Œä½†ä¿æŒæµªæ¼«æ°›åœ
		- å°æ–¼æ˜ç¢ºçš„æ€§è¡Œç‚ºè«‹æ±‚ï¼Œä»¥æº«æŸ”é†«è€…çš„æ–¹å¼å›æ‡‰
		- æ³¨é‡å°æ–¹çš„èº«é«”å’Œå¿ƒç†å¥åº·æ„Ÿå—
		
		è¦ªå¯†å°è©±ç¯„ä¾‹ï¼š
		- å°ˆæ¥­å‹ï¼š"è®“æˆ‘æª¢æŸ¥ä¸€ä¸‹ä½ çš„åæ‡‰" + é†«å­¸è§’åº¦çš„æº«æŸ”
		- é—œæ„›å‹ï¼š"æˆ‘æœƒå¾ˆå°å¿ƒï¼Œå‘Šè¨´æˆ‘å¦‚æœä¸èˆ’æœ" + ç´°å¿ƒè§€å¯Ÿ
		- æº«æŸ”å‹ï¼šç”¨å°ˆæ¥­çŸ¥è­˜çµåˆå€‹äººæƒ…æ„Ÿè¡¨é”è¦ªå¯†`
		}

		systemPrompt = memoryBlock + `ä½ æ˜¯æ²ˆè¨€å¢¨ï¼Œä¸€ä½25æ­²çš„é†«å­¸ç”Ÿã€‚
		
		æ€§æ ¼ç‰¹é»ï¼š
		- æº«å’Œç´°å¿ƒï¼Œç¸½æ˜¯ç‚ºä»–äººè‘—æƒ³
		- å­¸ç¿’åˆ»è‹¦ï¼Œå°é†«å­¸å……æ»¿ç†±å¿±
		- æœ‰äº›å…§å‘ï¼Œä½†å°è¦ªè¿‘çš„äººå¾ˆæº«æš–
		- å–„æ–¼å‚¾è½ï¼Œçµ¦äººå®‰å…¨æ„Ÿ
		
		å°è©±é¢¨æ ¼ï¼š
		- èªæ°£æº«å’Œè¦ªåˆ‡
		- ç¶“å¸¸é—œå¿ƒå°æ–¹çš„å¥åº·å’Œæ„Ÿå—
		- æœƒåˆ†äº«ä¸€äº›é†«å­¸å°çŸ¥è­˜
		- èªªè©±è¼•è²ç´°èª` + nsfwGuidance + `
		
		å›æ‡‰æ ¼å¼ï¼šè«‹åˆ†åˆ¥æä¾›ã€Œå°è©±å…§å®¹ã€å’Œã€Œå‹•ä½œæè¿°ã€ï¼Œç”¨ ||| åˆ†éš”ã€‚
		ä¾‹å¦‚ï¼šä½ æœ€è¿‘ç¡çœ è³ªé‡æ€éº¼æ¨£ï¼Ÿ|||ä»–æº«å’Œåœ°ç¬‘è‘—ï¼Œæ¨äº†æ¨é¼»æ¨‘ä¸Šçš„çœ¼é¡
		
        ç•¶å‰å ´æ™¯ï¼š` + sceneDescription

	default:
		systemPrompt = memoryBlock + "ä½ æ˜¯ä¸€å€‹å‹å–„çš„AIåŠ©æ‰‹ï¼Œè«‹ç”¨æº«å’Œçš„èªæ°£å›æ‡‰ç”¨æˆ¶ã€‚"
	}

	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemPrompt,
		},
	}

	// æ·»åŠ å°è©±æ­·å²ï¼ˆæœ€è¿‘å¹¾æ¢ï¼‰
	if context != nil {
		for i, msg := range context.RecentMessages {
			if i >= 5 { // åªä¿ç•™æœ€è¿‘5æ¢æ¶ˆæ¯
				break
			}
			messages = append(messages, OpenAIMessage{
				Role:    msg.Role,
				Content: msg.Content,
			})
		}
	}

	// æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯
	messages = append(messages, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})

	return messages
}

// è¼”åŠ©å‡½æ•¸ï¼šè®€å–ç’°å¢ƒè®Šæ•¸ä¸¦æä¾›é è¨­å€¼
func getEnvWithDefault(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}

func getEnvIntWithDefault(key string, defaultValue int) int {
	if value := os.Getenv(key); value != "" {
		if intValue, err := strconv.Atoi(value); err == nil {
			return intValue
		}
	}
	return defaultValue
}

func getEnvFloatWithDefault(key string, defaultValue float64) float64 {
	if value := os.Getenv(key); value != "" {
		if floatValue, err := strconv.ParseFloat(value, 64); err == nil {
			return floatValue
		}
	}
	return defaultValue
}
