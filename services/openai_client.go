package services

import (
	"context"
	"fmt"
	"strings"

	"github.com/clarencetw/thewavess-ai-core/utils"
	"github.com/sashabaranov/go-openai"
)

// OpenAIClient OpenAI å®¢æˆ¶ç«¯
type OpenAIClient struct {
	client      *openai.Client
	model       string
	maxTokens   int
	temperature float32
	baseURL     string
	isAzure     bool
}

// OpenAIRequest OpenAI è«‹æ±‚çµæ§‹
type OpenAIRequest struct {
	Model       string          `json:"model"`
	Messages    []OpenAIMessage `json:"messages"`
	MaxTokens   int             `json:"max_tokens"`
	Temperature float64         `json:"temperature"`
	User        string          `json:"user,omitempty"`
}

// OpenAIMessage OpenAI æ¶ˆæ¯çµæ§‹
type OpenAIMessage struct {
	Role    string `json:"role"` // system, user, assistant
	Content string `json:"content"`
}

// OpenAIResponse OpenAI å›æ‡‰çµæ§‹
type OpenAIResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Index   int `json:"index"`
		Message struct {
			Role    string `json:"role"`
			Content string `json:"content"`
		} `json:"message"`
		FinishReason string `json:"finish_reason"`
	} `json:"choices"`
	Usage struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
}

// NewOpenAIClient å‰µå»ºæ–°çš„ OpenAI å®¢æˆ¶ç«¯
func NewOpenAIClient() *OpenAIClient {
	// ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¼‰å…¥
	utils.LoadEnv()

	apiKey := utils.GetEnvWithDefault("OPENAI_API_KEY", "")
	if apiKey == "" {
		utils.Logger.Fatal("OPENAI_API_KEY is required but not set in environment")
	}

	// å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®ï¼Œæä¾›é è¨­å€¼
	model := utils.GetEnvWithDefault("OPENAI_MODEL", "gpt-4o")
	maxTokens := utils.GetEnvIntWithDefault("OPENAI_MAX_TOKENS", 1200)
	temperature := utils.GetEnvFloatWithDefault("OPENAI_TEMPERATURE", 0.8)

	// ç²å–è‡ªå®šç¾© API URLï¼Œæ”¯æ´ Azure æˆ–å…¶ä»–ç«¯é»
	baseURL := utils.GetEnvWithDefault("OPENAI_API_URL", "https://api.openai.com/v1")
	isAzure := false

	// æª¢æŸ¥æ˜¯å¦ç‚º Azure OpenAI
	if strings.Contains(baseURL, "azure.com") {
		isAzure = true
		// Azure OpenAI éœ€è¦ç‰¹æ®Šçš„ URL å’Œé…ç½®è™•ç†
		// ä¿æŒåŸå§‹ baseURLï¼Œè®“ go-openai åº«è™•ç†å…·é«”çš„ç«¯é»è·¯å¾‘
	}

	var client *openai.Client
	if isAzure {
		// Azure OpenAI éœ€è¦ç‰¹æ®Šé…ç½® - ä½¿ç”¨ DefaultAzureConfig
		config := openai.DefaultAzureConfig(apiKey, baseURL)
		// Azure éœ€è¦éƒ¨ç½²åç¨±ï¼Œé€šå¸¸å°±æ˜¯æ¨¡å‹åç¨±
		config.AzureModelMapperFunc = func(model string) string {
			return model // ä½¿ç”¨æ¨¡å‹åç¨±ä½œç‚ºéƒ¨ç½²åç¨±
		}
		client = openai.NewClientWithConfig(config)

		utils.Logger.WithFields(map[string]interface{}{
			"base_url":    baseURL,
			"api_type":    "azure",
			"api_version": config.APIVersion,
		}).Info("Using Azure OpenAI API")
	} else if baseURL != "https://api.openai.com/v1" {
		// å…¶ä»–è‡ªå®šç¾©ç«¯é»
		config := openai.DefaultConfig(apiKey)
		config.BaseURL = baseURL
		client = openai.NewClientWithConfig(config)

		utils.Logger.WithField("base_url", baseURL).Info("Using custom OpenAI API URL")
	} else {
		// ä½¿ç”¨é»˜èª OpenAI API
		client = openai.NewClient(apiKey)
	}

	return &OpenAIClient{
		client:      client,
		model:       model,
		maxTokens:   maxTokens,
		temperature: float32(temperature),
		baseURL:     baseURL,
		isAzure:     isAzure,
	}
}

// GenerateResponse ç”Ÿæˆå°è©±å›æ‡‰
func (c *OpenAIClient) GenerateResponse(ctx context.Context, request *OpenAIRequest) (*OpenAIResponse, error) {
	// è¨˜éŒ„è«‹æ±‚é–‹å§‹
	utils.Logger.WithFields(map[string]interface{}{
		"service":        "openai",
		"base_url":       c.baseURL,
		"model":          c.model,
		"max_tokens":     c.maxTokens,
		"temperature":    c.temperature,
		"user":           request.User,
		"messages_count": len(request.Messages),
	}).Info("OpenAI API request started")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„ prompt å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"model":   c.model,
			"user":    request.User,
		}).Info("ğŸ¤– OpenAI Request Details")

		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Info(fmt.Sprintf("ğŸ“ Prompt [%s]: %s", strings.ToUpper(msg.Role), msg.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, msg := range request.Messages {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"message_index":  i,
				"role":           msg.Role,
				"content_length": len(msg.Content),
			}).Debug("OpenAI request message")
		}
	}

	// è½‰æ›æ¶ˆæ¯æ ¼å¼
	messages := make([]openai.ChatCompletionMessage, len(request.Messages))
	for i, msg := range request.Messages {
		messages[i] = openai.ChatCompletionMessage{
			Role:    msg.Role,
			Content: msg.Content,
		}
	}

	// æ§‹å»ºè«‹æ±‚
	chatRequest := openai.ChatCompletionRequest{
		Model:       c.model,
		Messages:    messages,
		MaxTokens:   c.maxTokens,
		Temperature: c.temperature,
		User:        request.User,
	}

	// èª¿ç”¨ OpenAI API
	resp, err := c.client.CreateChatCompletion(ctx, chatRequest)

	if err != nil {
		utils.Logger.WithFields(map[string]interface{}{
			"service": "openai",
			"error":   err.Error(),
			"model":   c.model,
			"user":    request.User,
		}).Error("OpenAI API call failed")
		return nil, fmt.Errorf("failed OpenAI API call: %w", err)
	}

	// è¨˜éŒ„APIéŸ¿æ‡‰ä¿¡æ¯
	utils.Logger.WithFields(map[string]interface{}{
		"service":           "openai",
		"response_id":       resp.ID,
		"model":             resp.Model,
		"prompt_tokens":     resp.Usage.PromptTokens,
		"completion_tokens": resp.Usage.CompletionTokens,
		"total_tokens":      resp.Usage.TotalTokens,
		"choices_count":     len(resp.Choices),
	}).Info("OpenAI API response received")

	// é–‹ç™¼æ¨¡å¼ä¸‹è©³ç´°è¨˜éŒ„éŸ¿æ‡‰å…§å®¹
	if utils.GetEnvWithDefault("GO_ENV", "development") != "production" {
		utils.Logger.WithFields(map[string]interface{}{
			"service":     "openai",
			"response_id": resp.ID,
			"model":       resp.Model,
		}).Info("ğŸ¯ OpenAI Response Details")

		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Info(fmt.Sprintf("ğŸ’¬ Response [%d]: %s", i, choice.Message.Content))
		}
	} else {
		// ç”Ÿç”¢ç’°å¢ƒåªè¨˜éŒ„åŸºæœ¬ä¿¡æ¯
		for i, choice := range resp.Choices {
			utils.Logger.WithFields(map[string]interface{}{
				"service":        "openai",
				"choice_index":   i,
				"finish_reason":  choice.FinishReason,
				"content_length": len(choice.Message.Content),
			}).Debug("OpenAI response choice")
		}
	}

	// è½‰æ›å›æ‡‰æ ¼å¼
	response := &OpenAIResponse{
		ID:      resp.ID,
		Object:  resp.Object,
		Created: resp.Created,
		Model:   resp.Model,
		Usage: struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		}{
			PromptTokens:     resp.Usage.PromptTokens,
			CompletionTokens: resp.Usage.CompletionTokens,
			TotalTokens:      resp.Usage.TotalTokens,
		},
	}

	// è½‰æ›é¸é …
	for _, choice := range resp.Choices {
		response.Choices = append(response.Choices, struct {
			Index   int `json:"index"`
			Message struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		}{
			Index: choice.Index,
			Message: struct {
				Role    string `json:"role"`
				Content string `json:"content"`
			}{
				Role:    choice.Message.Role,
				Content: choice.Message.Content,
			},
			FinishReason: string(choice.FinishReason),
		})
	}

	return response, nil
}

// BuildCharacterPrompt æ§‹å»ºè§’è‰²æç¤ºè©ï¼ˆä½¿ç”¨çµ±ä¸€æ¨¡æ¿ï¼‰
func (c *OpenAIClient) BuildCharacterPrompt(characterID, userMessage string, conversationContext *ConversationContext, nsfwLevel int, chatMode string) []OpenAIMessage {

	// ä½¿ç”¨OpenAIå°ˆå±¬çš„promptæ§‹å»ºå™¨
	characterService := GetCharacterService()
	promptBuilder := NewOpenAIPromptBuilder(characterService)
	ctx := context.Background()
	systemPrompt := promptBuilder.
		WithCharacter(ctx, characterID).
		WithContext(conversationContext).
		WithNSFWLevel(nsfwLevel).
		WithUserMessage(userMessage).
		WithChatMode(chatMode).
		Build(ctx)

	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemPrompt,
		},
	}

	// æ·»åŠ å°è©±æ­·å²ï¼ˆæœ€è¿‘å¹¾æ¢ï¼‰
	if conversationContext != nil {
		for i, msg := range conversationContext.RecentMessages {
			if i >= 5 { // åªä¿ç•™æœ€è¿‘5æ¢æ¶ˆæ¯
				break
			}
			messages = append(messages, OpenAIMessage{
				Role:    msg.Role,
				Content: msg.Content,
			})
		}
	}

	// æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯
	messages = append(messages, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})

	return messages
}
