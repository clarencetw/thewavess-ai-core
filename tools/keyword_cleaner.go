package main

import (
	"bufio"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
)

// CleanupResult æ¸…ç†çµæœ
type CleanupResult struct {
	File             string
	OriginalCount    int
	CleanedCount     int
	RemovedDuplicates []string
	RemovedEmpty     int
}

func main() {
	fmt.Println("ğŸ§¹ é—œéµå­—æ¸…ç†å·¥å…·å•Ÿå‹•")
	fmt.Println("=" + strings.Repeat("=", 49))

	// æª¢æŸ¥æ˜¯å¦ç‚ºè‡ªå‹•æ¨¡å¼
	autoMode := len(os.Args) > 1 && os.Args[1] == "--auto"

	// ç¢ºèªç”¨æˆ¶æ„åœ–
	if !autoMode && !confirmAction() {
		fmt.Println("âŒ æ“ä½œå·²å–æ¶ˆ")
		return
	}

	if autoMode {
		fmt.Println("ğŸ¤– è‡ªå‹•æ¨¡å¼å•Ÿå‹•ï¼Œè·³éç¢ºèª")
	}

	// æ¸…ç†é—œéµå­—æª”æ¡ˆ
	results, err := cleanKeywordFiles()
	if err != nil {
		fmt.Printf("âŒ æ¸…ç†å¤±æ•—: %v\n", err)
		os.Exit(1)
	}

	// è¼¸å‡ºçµæœ
	printCleanupResults(results)

	fmt.Println("\nâœ… æ¸…ç†å®Œæˆ")
}

func confirmAction() bool {
	fmt.Println("âš ï¸  é€™å€‹å·¥å…·å°‡æœƒ:")
	fmt.Println("   1. ç§»é™¤æ¯å€‹æª”æ¡ˆå…§çš„é‡è¤‡é—œéµå­—")
	fmt.Println("   2. ç§»é™¤ç©ºç™½é—œéµå­—")
	fmt.Println("   3. é‡æ–°æ ¼å¼åŒ–é—œéµå­—åˆ—è¡¨")
	fmt.Println("   4. å‚™ä»½åŸæª”æ¡ˆç‚º .backup")
	fmt.Print("\næ˜¯å¦ç¹¼çºŒ? (y/N): ")

	reader := bufio.NewReader(os.Stdin)
	response, _ := reader.ReadString('\n')
	response = strings.TrimSpace(strings.ToLower(response))

	return response == "y" || response == "yes"
}

func cleanKeywordFiles() ([]CleanupResult, error) {
	basePath := "services"
	files := []string{
		"keyword_classifier_l1.go",
		"keyword_classifier_l2.go",
		"keyword_classifier_l3.go",
		"keyword_classifier_l4.go",
		"keyword_classifier_l5.go",
	}

	results := make([]CleanupResult, 0, len(files))

	for _, file := range files {
		filePath := filepath.Join(basePath, file)
		result, err := cleanSingleFile(filePath)
		if err != nil {
			return nil, fmt.Errorf("æ¸…ç†æª”æ¡ˆ %s å¤±æ•—: %v", file, err)
		}
		results = append(results, result)
	}

	return results, nil
}

func cleanSingleFile(filePath string) (CleanupResult, error) {
	result := CleanupResult{
		File: filepath.Base(filePath),
	}

	// è®€å–æª”æ¡ˆ
	content, err := os.ReadFile(filePath)
	if err != nil {
		return result, err
	}

	// å‚™ä»½åŸæª”æ¡ˆ
	backupPath := filePath + ".backup"
	err = os.WriteFile(backupPath, content, 0644)
	if err != nil {
		return result, fmt.Errorf("å‚™ä»½æª”æ¡ˆå¤±æ•—: %v", err)
	}

	// è§£æå’Œæ¸…ç†é—œéµå­—
	cleanedContent, cleanStats := cleanFileContent(string(content))
	result.OriginalCount = cleanStats.originalCount
	result.CleanedCount = cleanStats.cleanedCount
	result.RemovedDuplicates = cleanStats.removedDuplicates
	result.RemovedEmpty = cleanStats.removedEmpty

	// å¯«å›æª”æ¡ˆ
	err = os.WriteFile(filePath, []byte(cleanedContent), 0644)
	if err != nil {
		return result, err
	}

	fmt.Printf("âœ… %s: %d â†’ %d é—œéµå­—\n",
		result.File, result.OriginalCount, result.CleanedCount)

	return result, nil
}

type cleanStats struct {
	originalCount     int
	cleanedCount      int
	removedDuplicates []string
	removedEmpty      int
}

func cleanFileContent(content string) (string, cleanStats) {
	stats := cleanStats{}

	// æ‰¾åˆ°é—œéµå­—æ•¸çµ„çš„é–‹å§‹
	startPattern := regexp.MustCompile(`l\dKeywords := \[\]string\{`)

	lines := strings.Split(content, "\n")
	var keywordStart, keywordEnd int

	// æ‰¾åˆ°é—œéµå­—å€åŸŸ
	for i, line := range lines {
		if startPattern.MatchString(line) {
			keywordStart = i
		}
		if strings.Contains(line, "// æ·»åŠ åˆ°é—œéµå­—æ˜ å°„ä¸­") {
			keywordEnd = i
			break
		}
	}

	// æå–é—œéµå­—éƒ¨åˆ†
	keywordLines := lines[keywordStart+1 : keywordEnd-1]

	// è§£ææ‰€æœ‰é—œéµå­—
	re := regexp.MustCompile(`"([^"]+)"`)
	keywordMap := make(map[string]bool)
	var allKeywords []string

	for _, line := range keywordLines {
		matches := re.FindAllStringSubmatch(line, -1)
		for _, match := range matches {
			if len(match) > 1 {
				keyword := strings.TrimSpace(match[1])
				stats.originalCount++

				if keyword == "" {
					stats.removedEmpty++
					continue
				}

				if keywordMap[keyword] {
					stats.removedDuplicates = append(stats.removedDuplicates, keyword)
					continue
				}

				keywordMap[keyword] = true
				allKeywords = append(allKeywords, keyword)
			}
		}
	}

	stats.cleanedCount = len(allKeywords)

	// æŒ‰å­—æ¯é †åºæ’åº
	sort.Strings(allKeywords)

	// é‡æ–°ç”Ÿæˆé—œéµå­—éƒ¨åˆ†
	var newKeywordLines []string

	// ä¿ç•™è¨»é‡‹çµæ§‹ï¼Œé‡æ–°çµ„ç¹”é—œéµå­—
	currentSection := ""
	sectionKeywords := make(map[string][]string)
	var sectionOrder []string

	// æŒ‰åŸæœ‰çš„è¨»é‡‹åˆ†çµ„é‡æ–°çµ„ç¹”
	for _, line := range keywordLines {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "//") {
			currentSection = line
			if _, exists := sectionKeywords[currentSection]; !exists {
				sectionOrder = append(sectionOrder, currentSection)
				sectionKeywords[currentSection] = make([]string, 0)
			}
		} else if line != "" && currentSection != "" {
			// æå–è©²è¡Œçš„é—œéµå­—
			matches := re.FindAllStringSubmatch(line, -1)
			for _, match := range matches {
				if len(match) > 1 {
					keyword := strings.TrimSpace(match[1])
					if keyword != "" && keywordMap[keyword] {
						sectionKeywords[currentSection] = append(sectionKeywords[currentSection], keyword)
						delete(keywordMap, keyword) // æ¨™è¨˜ç‚ºå·²ä½¿ç”¨
					}
				}
			}
		}
	}

	// è™•ç†æ²’æœ‰åˆ†çµ„çš„é—œéµå­—
	orphanKeywords := make([]string, 0)
	for keyword := range keywordMap {
		orphanKeywords = append(orphanKeywords, keyword)
	}
	if len(orphanKeywords) > 0 {
		sort.Strings(orphanKeywords)
		sectionOrder = append(sectionOrder, "// === å…¶ä»–é—œéµå­— ===")
		sectionKeywords["// === å…¶ä»–é—œéµå­— ==="] = orphanKeywords
	}

	// ç”Ÿæˆæ–°çš„é—œéµå­—å…§å®¹
	for _, section := range sectionOrder {
		keywords := sectionKeywords[section]
		if len(keywords) == 0 {
			continue
		}

		newKeywordLines = append(newKeywordLines, "\t\t"+section)

		// æ¯è¡Œ8å€‹é—œéµå­—
		for i := 0; i < len(keywords); i += 8 {
			end := i + 8
			if end > len(keywords) {
				end = len(keywords)
			}

			lineKeywords := keywords[i:end]
			quotedKeywords := make([]string, len(lineKeywords))
			for j, kw := range lineKeywords {
				quotedKeywords[j] = fmt.Sprintf(`"%s"`, kw)
			}

			line := "\t\t" + strings.Join(quotedKeywords, ", ")
			if end < len(keywords) {
				line += ","
			} else if section != sectionOrder[len(sectionOrder)-1] {
				line += ","
			} else {
				// æœ€å¾Œä¸€è¡Œä¸åŠ é€—è™Ÿ
			}

			newKeywordLines = append(newKeywordLines, line)
		}

		if section != sectionOrder[len(sectionOrder)-1] {
			newKeywordLines = append(newKeywordLines, "")
		}
	}

	// é‡æ–°çµ„åˆå®Œæ•´å…§å®¹
	var newLines []string
	newLines = append(newLines, lines[:keywordStart+1]...)
	newLines = append(newLines, newKeywordLines...)
	newLines = append(newLines, lines[keywordEnd-1:]...)

	return strings.Join(newLines, "\n"), stats
}

func printCleanupResults(results []CleanupResult) {
	fmt.Println("\nğŸ“‹ æ¸…ç†çµæœæ‘˜è¦:")
	fmt.Println(strings.Repeat("-", 60))
	fmt.Printf("%-25s %-8s %-8s %-8s\n", "æª”æ¡ˆ", "åŸå§‹", "æ¸…ç†å¾Œ", "ç§»é™¤")
	fmt.Println(strings.Repeat("-", 60))

	totalOriginal := 0
	totalCleaned := 0
	totalRemoved := 0

	for _, result := range results {
		removed := result.OriginalCount - result.CleanedCount
		fmt.Printf("%-25s %-8d %-8d %-8d\n",
			result.File, result.OriginalCount, result.CleanedCount, removed)

		totalOriginal += result.OriginalCount
		totalCleaned += result.CleanedCount
		totalRemoved += removed
	}

	fmt.Println(strings.Repeat("-", 60))
	fmt.Printf("%-25s %-8d %-8d %-8d\n", "ç¸½è¨ˆ", totalOriginal, totalCleaned, totalRemoved)

	// é¡¯ç¤ºé‡è¤‡é—œéµå­—è©³æƒ…
	if totalRemoved > 0 {
		fmt.Println("\nğŸ”„ ç§»é™¤çš„é‡è¤‡é—œéµå­—:")
		fmt.Println(strings.Repeat("-", 60))
		for _, result := range results {
			if len(result.RemovedDuplicates) > 0 {
				fmt.Printf("%s: %v\n", result.File, result.RemovedDuplicates)
			}
		}
	}
}