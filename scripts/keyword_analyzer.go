package main

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"
)

// KeywordStats é—œéµå­—çµ±è¨ˆçµæ§‹
type KeywordStats struct {
	Level           int                 `json:"level"`
	File            string              `json:"file"`
	TotalKeywords   int                 `json:"total_keywords"`
	UniqueKeywords  int                 `json:"unique_keywords"`
	Duplicates      []string            `json:"duplicates"`
	Keywords        []string            `json:"keywords"`
	LengthStats     LengthStatistics    `json:"length_stats"`
}

// LengthStatistics é•·åº¦çµ±è¨ˆ
type LengthStatistics struct {
	Min     int     `json:"min"`
	Max     int     `json:"max"`
	Average float64 `json:"average"`
	Median  int     `json:"median"`
}

// ConflictInfo è¡çªä¿¡æ¯
type ConflictInfo struct {
	Keyword  string `json:"keyword"`
	Files    []string `json:"files"`
	Levels   []int  `json:"levels"`
	Count    int    `json:"count"`
}

// AnalysisReport åˆ†æå ±å‘Š
type AnalysisReport struct {
	Timestamp       string              `json:"timestamp"`
	TotalFiles      int                 `json:"total_files"`
	TotalKeywords   int                 `json:"total_keywords"`
	UniqueKeywords  int                 `json:"unique_keywords"`
	DuplicateCount  int                 `json:"duplicate_count"`
	CrossFileConflicts []ConflictInfo   `json:"cross_file_conflicts"`
	LevelStats      []KeywordStats      `json:"level_stats"`
	QualityScore    float64             `json:"quality_score"`
	Recommendations []string            `json:"recommendations"`
}

func main() {
	fmt.Println("ğŸ” é—œéµå­—åˆ†æå·¥å…·å•Ÿå‹•")
	fmt.Println(strings.Repeat("=", 50))

	// åˆ†æé—œéµå­—æª”æ¡ˆ
	report, err := analyzeKeywordFiles()
	if err != nil {
		fmt.Printf("âŒ åˆ†æå¤±æ•—: %v\n", err)
		os.Exit(1)
	}

	// è¼¸å‡ºçµæœ
	printReport(report)

	// å„²å­˜JSONå ±å‘Š
	saveJSONReport(report)

	fmt.Println("\nâœ… åˆ†æå®Œæˆ")
}

func analyzeKeywordFiles() (*AnalysisReport, error) {
	basePath := "services"
	files := []string{
		"keyword_classifier_l1.go",
		"keyword_classifier_l2.go",
		"keyword_classifier_l3.go",
		"keyword_classifier_l4.go",
		"keyword_classifier_l5.go",
	}

	report := &AnalysisReport{
		Timestamp: time.Now().Format("2006-01-02 15:04:05"),
		TotalFiles: len(files),
	}

	allKeywords := make(map[string][]int) // keyword -> levels
	levelStats := make([]KeywordStats, 0, len(files))

	// åˆ†ææ¯å€‹æª”æ¡ˆ
	for i, file := range files {
		level := i + 1
		filePath := filepath.Join(basePath, file)

		keywords, err := extractKeywords(filePath)
		if err != nil {
			return nil, fmt.Errorf("è®€å–æª”æ¡ˆ %s å¤±æ•—: %v", file, err)
		}

		// çµ±è¨ˆæœ¬æª”æ¡ˆ
		stats := analyzeFileKeywords(level, file, keywords)
		levelStats = append(levelStats, stats)

		// è¨˜éŒ„åˆ°å…¨åŸŸçµ±è¨ˆ
		for _, keyword := range keywords {
			allKeywords[keyword] = append(allKeywords[keyword], level)
		}

		report.TotalKeywords += len(keywords)
	}

	// è¨ˆç®—æ•´é«”çµ±è¨ˆ
	report.UniqueKeywords = len(allKeywords)
	report.LevelStats = levelStats

	// æ‰¾å‡ºè·¨æª”æ¡ˆè¡çª
	conflicts := findCrossFileConflicts(allKeywords)
	report.CrossFileConflicts = conflicts
	report.DuplicateCount = len(conflicts)

	// è¨ˆç®—å“è³ªåˆ†æ•¸
	report.QualityScore = calculateQualityScore(report)

	// ç”Ÿæˆå»ºè­°
	report.Recommendations = generateRecommendations(report)

	return report, nil
}

func extractKeywords(filePath string) ([]string, error) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	// ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–æ‰€æœ‰quotedå­—ç¬¦ä¸²
	re := regexp.MustCompile(`"([^"]+)"`)
	matches := re.FindAllStringSubmatch(string(content), -1)

	keywords := make([]string, 0, len(matches))
	for _, match := range matches {
		if len(match) > 1 {
			keyword := strings.TrimSpace(match[1])
			if keyword != "" {
				keywords = append(keywords, keyword)
			}
		}
	}

	return keywords, nil
}

func analyzeFileKeywords(level int, file string, keywords []string) KeywordStats {
	// å»é‡ä¸¦æ‰¾å‡ºé‡è¤‡é …
	uniqueMap := make(map[string]int)
	duplicates := make([]string, 0)

	for _, keyword := range keywords {
		uniqueMap[keyword]++
		if uniqueMap[keyword] == 2 {
			duplicates = append(duplicates, keyword)
		}
	}

	// è¨ˆç®—é•·åº¦çµ±è¨ˆ
	lengths := make([]int, len(keywords))
	totalLength := 0
	for i, keyword := range keywords {
		lengths[i] = len(keyword)
		totalLength += len(keyword)
	}

	sort.Ints(lengths)

	lengthStats := LengthStatistics{
		Min:     lengths[0],
		Max:     lengths[len(lengths)-1],
		Average: float64(totalLength) / float64(len(keywords)),
		Median:  lengths[len(lengths)/2],
	}

	return KeywordStats{
		Level:          level,
		File:           file,
		TotalKeywords:  len(keywords),
		UniqueKeywords: len(uniqueMap),
		Duplicates:     duplicates,
		Keywords:       keywords,
		LengthStats:    lengthStats,
	}
}

func findCrossFileConflicts(allKeywords map[string][]int) []ConflictInfo {
	conflicts := make([]ConflictInfo, 0)

	for keyword, levels := range allKeywords {
		// å»é‡levelsä¸¦æ’åº
		uniqueLevels := make(map[int]bool)
		for _, level := range levels {
			uniqueLevels[level] = true
		}

		// åªæœ‰ç•¶é—œéµå­—å‡ºç¾åœ¨å¤šå€‹ä¸åŒç­‰ç´šæ™‚æ‰ç®—è¡çª
		if len(uniqueLevels) > 1 {
			levelList := make([]int, 0, len(uniqueLevels))
			fileList := make([]string, 0, len(uniqueLevels))

			for level := range uniqueLevels {
				levelList = append(levelList, level)
				fileList = append(fileList, fmt.Sprintf("L%d", level))
			}

			sort.Ints(levelList)

			conflicts = append(conflicts, ConflictInfo{
				Keyword: keyword,
				Files:   fileList,
				Levels:  levelList,
				Count:   len(levels),
			})
		}
	}

	// æŒ‰è¡çªæ•¸é‡æ’åº
	sort.Slice(conflicts, func(i, j int) bool {
		return conflicts[i].Count > conflicts[j].Count
	})

	return conflicts
}

func calculateQualityScore(report *AnalysisReport) float64 {
	score := 100.0

	// é‡è¤‡é—œéµå­—æ‰£åˆ† (æ¯å€‹é‡è¤‡é—œéµå­—æ‰£0.5åˆ†)
	score -= float64(report.DuplicateCount) * 0.5

	// æª”æ¡ˆé–“ä¸å¹³è¡¡æ‰£åˆ† (é™åˆ¶æœ€å¤§æ‰£åˆ†)
	if len(report.LevelStats) > 0 && report.TotalKeywords > 0 {
		avgKeywords := float64(report.TotalKeywords) / float64(len(report.LevelStats))
		totalDeviation := 0.0
		for _, stats := range report.LevelStats {
			deviation := float64(stats.TotalKeywords) - avgKeywords
			if deviation < 0 {
				deviation = -deviation
			}
			totalDeviation += deviation / avgKeywords
		}
		// é™åˆ¶ä¸å¹³è¡¡æ‰£åˆ†æœ€å¤š20åˆ†
		imbalancePenalty := totalDeviation * 2
		if imbalancePenalty > 20 {
			imbalancePenalty = 20
		}
		score -= imbalancePenalty
	}

	// å¦‚æœæ²’æœ‰é‡è¤‡é—œéµå­—ï¼Œçµ¦äºˆçå‹µ
	if report.DuplicateCount == 0 {
		score += 5
	}

	// ç¢ºä¿åˆ†æ•¸åœ¨0-100ç¯„åœå…§
	if score < 0 {
		score = 0
	}
	if score > 100 {
		score = 100
	}

	return score
}

func generateRecommendations(report *AnalysisReport) []string {
	recommendations := make([]string, 0)

	if report.DuplicateCount > 0 {
		recommendations = append(recommendations,
			fmt.Sprintf("ç™¼ç¾ %d å€‹è·¨æª”æ¡ˆé‡è¤‡é—œéµå­—ï¼Œå»ºè­°æ¸…ç†é‡è¤‡é …", report.DuplicateCount))
	}

	if report.QualityScore < 90 {
		recommendations = append(recommendations, "æ•´é«”å“è³ªåˆ†æ•¸åä½ï¼Œå»ºè­°æª¢æŸ¥é—œéµå­—åˆ†ä½ˆå’Œé‡è¤‡å•é¡Œ")
	}

	// æª¢æŸ¥å„æª”æ¡ˆé—œéµå­—æ•¸é‡å¹³è¡¡
	if len(report.LevelStats) > 0 {
		maxKeywords := 0
		minKeywords := report.LevelStats[0].TotalKeywords

		for _, stats := range report.LevelStats {
			if stats.TotalKeywords > maxKeywords {
				maxKeywords = stats.TotalKeywords
			}
			if stats.TotalKeywords < minKeywords {
				minKeywords = stats.TotalKeywords
			}
		}

		if maxKeywords > minKeywords*3 {
			recommendations = append(recommendations, "é—œéµå­—åˆ†ä½ˆä¸å¹³è¡¡ï¼Œå»ºè­°èª¿æ•´å„ç­‰ç´šçš„é—œéµå­—æ•¸é‡")
		}
	}

	return recommendations
}

func printReport(report *AnalysisReport) {
	fmt.Printf("ğŸ“Š é—œéµå­—åˆ†æå ±å‘Š - %s\n", report.Timestamp)
	fmt.Println(strings.Repeat("=", 60))

	// æ•´é«”çµ±è¨ˆ
	fmt.Printf("ğŸ“ ç¸½æª”æ¡ˆæ•¸: %d\n", report.TotalFiles)
	fmt.Printf("ğŸ“ ç¸½é—œéµå­—: %d\n", report.TotalKeywords)
	fmt.Printf("ğŸ”‘ å”¯ä¸€é—œéµå­—: %d\n", report.UniqueKeywords)
	fmt.Printf("ğŸ”„ é‡è¤‡é—œéµå­—: %d\n", report.DuplicateCount)
	fmt.Printf("â­ å“è³ªåˆ†æ•¸: %.1f/100\n", report.QualityScore)

	// å„æª”æ¡ˆçµ±è¨ˆ
	fmt.Println("\nğŸ“‹ å„æª”æ¡ˆè©³ç´°çµ±è¨ˆ:")
	fmt.Println(strings.Repeat("-", 60))
	fmt.Printf("%-6s %-8s %-8s %-8s %-10s\n", "ç­‰ç´š", "ç¸½æ•¸", "å”¯ä¸€", "é‡è¤‡", "å¹³å‡é•·åº¦")
	fmt.Println(strings.Repeat("-", 60))

	for _, stats := range report.LevelStats {
		fmt.Printf("L%-5d %-8d %-8d %-8d %.1f\n",
			stats.Level,
			stats.TotalKeywords,
			stats.UniqueKeywords,
			len(stats.Duplicates),
			stats.LengthStats.Average)
	}

	// è·¨æª”æ¡ˆè¡çª (åªé¡¯ç¤ºå‰10å€‹)
	if len(report.CrossFileConflicts) > 0 {
		fmt.Println("\nâš ï¸  è·¨æª”æ¡ˆè¡çª (å‰10å€‹):")
		fmt.Println(strings.Repeat("-", 60))
		count := len(report.CrossFileConflicts)
		if count > 10 {
			count = 10
		}

		for i := 0; i < count; i++ {
			conflict := report.CrossFileConflicts[i]
			fmt.Printf("'%s' å‡ºç¾åœ¨: %v\n", conflict.Keyword, conflict.Files)
		}

		if len(report.CrossFileConflicts) > 10 {
			fmt.Printf("... é‚„æœ‰ %d å€‹è¡çª (è©³è¦‹JSONå ±å‘Š)\n", len(report.CrossFileConflicts)-10)
		}
	}

	// å»ºè­°
	if len(report.Recommendations) > 0 {
		fmt.Println("\nğŸ’¡ æ”¹é€²å»ºè­°:")
		fmt.Println(strings.Repeat("-", 60))
		for i, rec := range report.Recommendations {
			fmt.Printf("%d. %s\n", i+1, rec)
		}
	}
}

func saveJSONReport(report *AnalysisReport) {
	filename := fmt.Sprintf("scripts/keyword_analysis_%s.json",
		time.Now().Format("20060102_150405"))

	data, err := json.MarshalIndent(report, "", "  ")
	if err != nil {
		fmt.Printf("âŒ JSONåºåˆ—åŒ–å¤±æ•—: %v\n", err)
		return
	}

	err = os.WriteFile(filename, data, 0644)
	if err != nil {
		fmt.Printf("âŒ å„²å­˜JSONå ±å‘Šå¤±æ•—: %v\n", err)
		return
	}

	fmt.Printf("ğŸ’¾ è©³ç´°å ±å‘Šå·²å„²å­˜: %s\n", filename)
}