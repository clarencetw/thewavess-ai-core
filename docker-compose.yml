services:
  # Thewavess AI Core API
  api:
    build:
      context: .
      args:
        VERSION: ${VERSION:-v1.0.0}
        BUILD_TIME: ${BUILD_TIME:-unknown}
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    ports:
      - "8080:8080"
    env_file:
      - .env
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    environment:
      - GIN_MODE=release
      - GO_ENV=development
      - PORT=8080
      - LOG_LEVEL=${LOG_LEVEL:-debug}
      - ENVIRONMENT=${ENVIRONMENT:-development}
      # Database Configuration
      - DB_USER=${DB_USER:-thewavess}
      - DB_PASSWORD=${DB_PASSWORD:-password}
      - DB_HOST=postgres  # Docker service name
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-thewavess_ai_core}
      - DB_SSLMODE=disable
      # Redis Configuration  
      - REDIS_URL=redis://redis:6379/0
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-1200}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.8}
      - OPENAI_API_URL=${OPENAI_API_URL:-https://api.openai.com/v1}
      # OpenAI Advanced Parameters (Optional)
      - OPENAI_SEED=${OPENAI_SEED:-}
      - OPENAI_LOGPROBS=${OPENAI_LOGPROBS:-}
      - OPENAI_TOP_LOGPROBS=${OPENAI_TOP_LOGPROBS:-}
      - OPENAI_SERVICE_TIER=${OPENAI_SERVICE_TIER:-auto}
      # Mistral Configuration
      - MISTRAL_API_KEY=${MISTRAL_API_KEY:-}
      - MISTRAL_MODEL=${MISTRAL_MODEL:-mistral-medium-latest}
      - MISTRAL_MAX_TOKENS=${MISTRAL_MAX_TOKENS:-1200}
      - MISTRAL_TEMPERATURE=${MISTRAL_TEMPERATURE:-0.8}
      # Grok Configuration
      - GROK_API_KEY=${GROK_API_KEY:-}
      - GROK_MODEL=${GROK_MODEL:-grok-4-fast}
      - GROK_MAX_TOKENS=${GROK_MAX_TOKENS:-2000}
      - GROK_TEMPERATURE=${GROK_TEMPERATURE:-0.9}
      - GROK_API_URL=${GROK_API_URL:-https://api.x.ai/v1}
      # Security
      - JWT_SECRET=${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # CORS Configuration
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS:-*}
      - CORS_ALLOWED_METHODS=${CORS_ALLOWED_METHODS:-GET,POST,PUT,PATCH,DELETE,HEAD,OPTIONS}
      - CORS_ALLOWED_HEADERS=${CORS_ALLOWED_HEADERS:-Origin,Content-Length,Content-Type,Authorization,X-Requested-With,Accept,Accept-Encoding,Accept-Language,Connection,Host,User-Agent}
      - CORS_EXPOSED_HEADERS=${CORS_EXPOSED_HEADERS:-}
      # TTS (Optional)
      - TTS_API_KEY=${TTS_API_KEY:-}
      # NSFW Classification: Using built-in keyword classifier
      # Swagger API Host Configuration
      - API_HOST=${API_HOST:-localhost:8080}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/api/v1/monitor/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=thewavess_ai_core
      - POSTGRES_USER=thewavess
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres/data:/var/lib/postgresql/data
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U thewavess -d thewavess_ai_core"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

# 使用 Docker 預設 bridge 網路，簡單有效
# 所有服務自動在同一網路中，可通過服務名稱互相通信
